{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "url = 'https://ndownloader.figshare.com/files/18543320?private_link=74a5ea79d76ad66a8af8'\n",
    "\n",
    "#Extract Columns\n",
    "survey = pd.read_excel(url)\n",
    "raw_cols = survey.columns\n",
    "\n",
    "#Create df\n",
    "survey = pd.read_excel(url, header=None, skiprows = 2, names = raw_cols)\n",
    "\n",
    "# #Set data path\n",
    "# d_path = 'data/'\n",
    "\n",
    "# #Import survey data from .csv\n",
    "# survey = pd.read_csv(d_path + 'nature_phdsurvey_2019.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define wrangle function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to clean data\n",
    "#The data dictionary provided with the article does not match the dataset well. Check readme for explanation as to why I removed some columns. I think the question #'s got mislabeled somehow.\n",
    "\n",
    "def clean_data(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    print(f'The survey dataset was originally {X.shape}')\n",
    "    \n",
    "    #Filter out 300 rows that chose to not answer target question (those that preferred not to answer)\n",
    "    X = X[((X['Q28'] == 'Yes') | (X['Q28'] == 'No'))]\n",
    "    \n",
    "    #Drop columns containing unique metadata for each test\n",
    "    X = X.drop(columns = ['ID.format', 'ID.endDate', 'ID.completed', 'ID.site', 'ID.date', 'ID.start', 'ID.end', 'ID.time'])\n",
    "    \n",
    "    #Drop columns with extra / specific data. Most are a step down from 'Other' answers in survey\n",
    "    X = X.drop(columns = ['Q1.a', 'Q2', 'Q3.a', 'Q6', 'Q6.a', 'Q7', 'Q7.a', 'Q8', 'Q8.a', 'Q9', 'Q9.a', 'Q10', 'Q10.a', 'Q11', 'Q11.a',\n",
    "                         'Q12.a', 'Q14', 'Q14.a', 'Q15.a', 'Q15.b', 'Q15.c', 'Q15.d', 'Q15.e', 'Q15.f', 'Q15.g', 'Q15.h', 'Q15.i', 'Q15.j',\n",
    "                          'Q15.k', 'Q15.l', 'Q15.m', 'Q15.n', 'Q16','Q17.a', 'Q25.a', 'Q26', 'Q29', 'Q29.a', 'Q32:1', 'Q32:2', 'Q32:3', 'Q32:4', \n",
    "                          'Q32:5', 'Q32:6', 'Q32:7', 'Q32.a', 'Q33', 'Q35:1', 'Q35:2', 'Q35:3', 'Q35:4', 'Q35:5', 'Q35:6', 'Q35:7', 'Q35:8', 'Q35:9', \n",
    "                          'Q35.a', 'Q36.a','Q37.a', 'Q37.b', 'Q37.c', 'Q37.d', 'Q37.e','Q39:1', 'Q39:2', 'Q39:3', 'Q39:4', 'Q39:5', 'Q39:6', 'Q39:7', \n",
    "                          'Q39:8', 'Q39:9', 'Q39:1', 'Q39:2', 'Q39:3', 'Q39:4', 'Q39:5', 'Q39:6', 'Q39:7', 'Q39:8', 'Q39:9', 'Q48:1', 'Q48:2', 'Q48:3', \n",
    "                          'Q48:4', 'Q48:5', 'Q48:6', 'Q48:7', 'Q48.a', 'Q49:8', 'Q49.a', 'Q52.a', 'Q53:1', 'Q53:2', 'Q53:3', 'Q53:4', 'Q53:5', 'Q53:6', 'Q53:7', \n",
    "                          'Q53.a', 'Q54:5', 'Q54.a', 'Q55', 'Q58.a', 'Q59:1', 'Q59:2', 'Q59:3'])\n",
    "    \n",
    "    #Q3 Replace 'Other, please specify with other'\n",
    "    X['Q3'] = X['Q3'].replace('Other, please specify', 'Other')\n",
    "    \n",
    "    #Q4: Are you studying where you grew up?\n",
    "    X['Q4'] = X['Q4'].replace('yes', 1)\n",
    "    X['Q4'] = X['Q4'].replace('no', 0)\n",
    "    \n",
    "    #Q12:1-:12 1 or 0 if they went to graduate school for this reason\n",
    "    Q12_ans = ['Q12:1', 'Q12:2', 'Q12:3', \"Q12:4\", 'Q12:5', 'Q12:6', 'Q12:7', 'Q12:8', 'Q12:9', 'Q12:10', 'Q12:11']\n",
    "    for i in Q12_ans:\n",
    "        X[i].fillna(0, inplace= True)\n",
    "    X['Q12:1'] = (X['Q12:1'].replace('To study at a specific university', 1))\n",
    "    X['Q12:2'] = (X['Q12:2'].replace('Lack of quality PhD programmes in my home country', 1))\n",
    "    X['Q12:3'] = (X['Q12:3'].replace('Lack of funding opportunities in my home country', 1))\n",
    "    X['Q12:4'] = (X['Q12:4'].replace('Lack of PhD programmes in my subject of choice', 1))\n",
    "    X['Q12:5'] = (X['Q12:5'].replace('Chance to pursue a specific research question', 1))\n",
    "    X['Q12:6'] = (X['Q12:6'].replace('Higher salaries post-study', 1))\n",
    "    X['Q12:7'] = (X['Q12:7'].replace('More job opportunities post-study', 1))\n",
    "    X['Q12:8'] = (X['Q12:8'].replace('Family reasons', 1))\n",
    "    X['Q12:9'] = (X['Q12:9'].replace('To experience another culture', 1))\n",
    "    X['Q12:10'] = (X['Q12:10'].replace('Political reasons', 1))\n",
    "    X['Q12:11'] = (X['Q12:11'].replace('Other, please specify', 1))\n",
    "    \n",
    "    #Q18a - How satisfied are you with your decision to pursue a phd?\n",
    "    X['Q18.a'] = (X['Q18.a'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    \n",
    "    #Q19a - How satisfied are you with your phd experience?\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('4 = Neither satisfied nor dissatisfied', 4))\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('1 = Not at all satisfied', 1))\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('7 = Extremely satisfied', 7))\n",
    "    \n",
    "    #Q21a:i & Q22a:i - How satisfied are you with x (Ordinal)\n",
    "    q_21s = ['Q21.a', 'Q21.b', 'Q21.c', 'Q21.d', 'Q21.e', 'Q21.f', 'Q21.g', 'Q21.h', 'Q21.i', 'Q22.a', 'Q22.b', 'Q22.c', 'Q22.d', 'Q22.e', 'Q22.f', 'Q22.g', 'Q22.h', 'Q22.i']\n",
    "    for every in q_21s:\n",
    "        X[q_21s] = (X[q_21s].replace('4 = Neither satisfied nor dissatisfied', 4))\n",
    "        X[q_21s] = (X[q_21s].replace('1 = Not at all satisfied', 1))\n",
    "        X[q_21s] = (X[q_21s].replace('7 = Extremely satisfied', 7))\n",
    "        \n",
    "    #Q24 Workload on average (Ordinal)\n",
    "    X['Q24'] = (X['Q24'].replace('41-50 hours','41-50'))\n",
    "    X['Q24'] = (X['Q24'].replace('51-60 hours','51-60'))\n",
    "    X['Q24'] = (X['Q24'].replace('61-70 hours','61-70'))\n",
    "    X['Q24'] = (X['Q24'].replace('71-80 hours','71-80'))\n",
    "    X['Q24'] = (X['Q24'].replace('21-30 hours','21-30'))\n",
    "    X['Q24'] = (X['Q24'].replace('31-40 hours','31-40'))\n",
    "    X['Q24'] = (X['Q24'].replace('Less than 11 hours','0-10'))\n",
    "    X['Q24'] = (X['Q24'].replace('More than 80 hours','81 and up'))\n",
    "    \n",
    "    #Q25.a - extra for other\n",
    "    X['Q25'] = (X['Q25'].replace('Other, please specify', 'Other'))\n",
    "    \n",
    "    #Q30.a - Q30.f - strongly agree or disagree\n",
    "    X['Q30.a'] = (X['Q30.a'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.b'] = (X['Q30.b'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.c'] = (X['Q30.c'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.d'] = (X['Q30.d'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.e'] = (X['Q30.e'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.f'] = (X['Q30.f'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "\n",
    "    #Q34 Did you feel discriminated against or harassed? No issue\n",
    "    X['Q34'].fillna('Prefer not to say', inplace=True)\n",
    "    \n",
    "    #Q47 : Which of these are most difficult based on your discipline\n",
    "    X['Q47:1'] = (X['Q47:1'].replace('Learning what career possibilities exist', 1))\n",
    "    X['Q47:2'] = (X['Q47:2'].replace('Finding research careers within academia', 1))\n",
    "    X['Q47:3'] = (X['Q47:3'].replace('Finding research careers within industry', 1))\n",
    "    X['Q47:4'] = (X['Q47:4'].replace('Finding research careers within government', 1))\n",
    "    X['Q47:5'] = (X['Q47:5'].replace('Finding research careers within charity/non-profit', 1))\n",
    "    X['Q47:6'] = (X['Q47:6'].replace('Obtaining skills for careers in industry', 1))\n",
    "    X['Q47:7'] = (X['Q47:7'].replace('Obtaining skills for careers in non-profits \\xa0', 1))\n",
    "    X['Q47:8'] = (X['Q47:8'].replace('Finding non-research careers that use my skills', 1))\n",
    "    X['Q47:1'].fillna(0, inplace= True)\n",
    "    X['Q47:2'].fillna(0, inplace= True)\n",
    "    X['Q47:3'].fillna(0, inplace= True)\n",
    "    X['Q47:4'].fillna(0, inplace= True)\n",
    "    X['Q47:5'].fillna(0, inplace= True)\n",
    "    X['Q47:6'].fillna(0, inplace= True)\n",
    "    X['Q47:7'].fillna(0, inplace= True)\n",
    "    X['Q47:8'].fillna(0, inplace= True)\n",
    "    \n",
    "    #Q49 - Which of the following do you think is needed\n",
    "    X['Q49:1'].fillna(0, inplace= True)\n",
    "    X['Q49:2'].fillna(0, inplace= True)\n",
    "    X['Q49:3'].fillna(0, inplace= True)\n",
    "    X['Q49:4'].fillna(0, inplace= True)\n",
    "    X['Q49:5'].fillna(0, inplace= True)\n",
    "    X['Q49:6'].fillna(0, inplace= True)\n",
    "    X['Q49:1'] = (X['Q49:1'].replace('Lower competition for grants', 1))\n",
    "    X['Q49:2'] = (X['Q49:2'].replace('Mentorship with individuals in my field/department/institution', 1))\n",
    "    X['Q49:3'] = (X['Q49:3'].replace('Gender-specific mentorship with individuals in my field/department/institution', 1))\n",
    "    X['Q49:4'] = (X['Q49:4'].replace('Better data/information about available career opportunities', 1))\n",
    "    X['Q49:5'] = (X['Q49:5'].replace('A record of, or data on, career paths of previous graduates from my programme', 1))\n",
    "    X['Q49:6'] = (X['Q49:6'].replace('More jobs in academia', 1))\n",
    "    X['Q49:7'] = (X['Q49:7'].replace('Grants to help PhD holders transition to permanent positions', 1))\n",
    "    \n",
    "    #Q52:1 - 52:8 Which, if any, of the following activities have you done to advance your career? \n",
    "    X['Q52:1'].fillna(0, inplace= True)\n",
    "    X['Q52:2'].fillna(0, inplace= True)\n",
    "    X['Q52:3'].fillna(0, inplace= True)\n",
    "    X['Q52:4'].fillna(0, inplace= True)\n",
    "    X['Q52:5'].fillna(0, inplace= True)\n",
    "    X['Q52:6'].fillna(0, inplace= True)\n",
    "    X['Q52:7'].fillna(0, inplace= True)\n",
    "    X['Q52:8'].fillna(0, inplace= True)\n",
    "    X['Q52:1'] = (X['Q52:1'].replace('Attended career seminars and/or workshops',1)) \n",
    "    X['Q52:2'] = (X['Q52:2'].replace('Attended networking events',1))\n",
    "    X['Q52:3'] = (X['Q52:3'].replace('Developed my social media profile',1))\n",
    "    X['Q52:4'] = (X['Q52:4'].replace('Worked out an individualized development plan',1))\n",
    "    X['Q52:5'] = (X['Q52:5'].replace('Discussed my career future with a supervisor/PI',1))\n",
    "    X['Q52:6'] = (X['Q52:6'].replace('Discussed my career future with a mentor',1))\n",
    "    X['Q52:7'] = (X['Q52:7'].replace('Discussed my career future with a careers counsellor at my institution',1))\n",
    "    X['Q52:8'] = (X['Q52:8'].replace('Other, please specify',1))\n",
    "    \n",
    "    #Q54:1\tQ54:2 Q54:3 Q54:4 Q54:5 Q54.a what would you do differently\n",
    "    X['Q54:1'].fillna(0, inplace= True)\n",
    "    X['Q54:2'].fillna(0, inplace= True)\n",
    "    X['Q54:3'].fillna(0, inplace= True)\n",
    "    X['Q54:4'].fillna(0, inplace= True)\n",
    "    X['Q54:1'] = (X['Q54:1'].replace('Change area of study',1))\n",
    "    X['Q54:2'] = (X['Q54:2'].replace('Change supervisor/PI ',1))\n",
    "    X['Q54:3'] = (X['Q54:3'].replace('Not pursue a PhD at all',1))\n",
    "    X['Q54:4'] = (X['Q54:4'].replace('Nothing',1))\n",
    "\n",
    "    #Q58\n",
    "    X['Q58:1'].fillna(0, inplace= True)\n",
    "    X['Q58:2'].fillna(0, inplace= True)\n",
    "    X['Q58:3'].fillna(0, inplace= True)\n",
    "    X['Q58:4'].fillna(0, inplace= True)\n",
    "    X['Q58:5'].fillna(0, inplace= True)\n",
    "    X['Q58:6'].fillna(0, inplace= True)\n",
    "    X['Q58:7'].fillna(0, inplace= True)\n",
    "    X['Q58:8'].fillna(0, inplace= True)\n",
    "    X['Q58:9'].fillna(0, inplace= True)\n",
    "    X['Q58:10'].fillna(0, inplace= True)\n",
    "    X['Q58:11'].fillna(0, inplace= True)\n",
    "    X['Q58:12'].fillna(0, inplace= True)\n",
    "    X['Q58:1'] = (X['Q58:1'].replace('Caucasian',1))\n",
    "    X['Q58:2'] = (X['Q58:2'].replace('Latino/Hispanic',1))\n",
    "    X['Q58:3'] = (X['Q58:3'].replace('Middle Eastern',1))\n",
    "    X['Q58:4'] = (X['Q58:4'].replace('African',1))\n",
    "    X['Q58:5'] = (X['Q58:5'].replace('Caribbean',1))\n",
    "    X['Q58:6'] = (X['Q58:6'].replace('South Asian',1))\n",
    "    X['Q58:7'] = (X['Q58:7'].replace('East Asian',1))\n",
    "    X['Q58:8'] = (X['Q58:8'].replace('Pacific Islander',1))\n",
    "    X['Q58:9'] = (X['Q58:9'].replace('American Indian',1))\n",
    "    X['Q58:10'] = (X['Q58:10'].replace('Mixed ethnicity',1))\n",
    "    X['Q58:11'] = (X['Q58:11'].replace('Other, please specify',1))\n",
    "    X['Q58:12'] = (X['Q58:12'].replace('Prefer not to say',1))\n",
    "\n",
    "    #Q59\n",
    "    X['Q59:4'] = X['Q59:4'].replace('No', 0)\n",
    "    X['Q59:4'].fillna(1, inplace= True)\n",
    "    \n",
    "    #Print out new shape after wrangling\n",
    "    print(f'After wrangling, the dataset is {X.shape}')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe, X feature matrix, and y target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The survey dataset was originally (6812, 274)\n",
      "After wrangling, the dataset is (6512, 168)\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe from raw data\n",
    "df = clean_data(survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_test is (6512, 167)\n",
      "The shape of y_test is (6512,)\n",
      "The model will be built to predict whether an individual will reach out for help with anxiety and depression (Q28)\n"
     ]
    }
   ],
   "source": [
    "#Creating X_test, y_test from features, target\n",
    "X_train = df.drop(columns='Q28')\n",
    "features = X_train.columns.tolist()\n",
    "target = 'Q28'\n",
    "y_train = df[target]\n",
    "\n",
    "print(f'The shape of X_test is {X_train.shape}')\n",
    "print(f'The shape of y_test is {y_train.shape}')\n",
    "print(f'The model will be built to predict whether an individual will reach out for help with anxiety and depression ({target})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269963144963145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#Sklearn baseline (sklearn dummyclassifier)\n",
    "\n",
    "X_baseline = df.drop(columns='Q28')\n",
    "y_baseline = df['Q28']\n",
    "\n",
    "#Create baseline model\n",
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(X_baseline, y_baseline)\n",
    "\n",
    "\n",
    "baseline.score(X_baseline, y_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic baseline accuracy: 0.6845823095823096\n"
     ]
    }
   ],
   "source": [
    "#Create logistic regression baseline\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    LogisticRegression(solver = 'lbfgs',n_jobs = -1, random_state = 42, max_iter = 1000, verbose = 5)\n",
    ")\n",
    "\n",
    "log_model = log_pipeline.fit(X_train, y_train)\n",
    "print('Logistic baseline accuracy:', log_model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-2)]: Done  47 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-2)]: Done  71 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-2)]: Done  84 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-2)]: Done  98 out of 100 | elapsed:  5.5min remaining:    6.6s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'randomforestclassifier__max_depth': 15, 'randomforestclassifier__max_features': 0.2972473260117179, 'randomforestclassifier__min_samples_leaf': 10, 'randomforestclassifier__min_samples_split': 15, 'randomforestclassifier__n_estimators': 300}\n",
      "Cross-validation Accuracy -0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Create random forest pipeline\n",
    "rf = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    RandomForestClassifier(random_state = 42, n_jobs = -1)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__n_estimators': [10, 50, 100, 300, 500],\n",
    "    'randomforestclassifier__max_depth': [5, 8, 10, 15, 20, None], \n",
    "    'randomforestclassifier__min_samples_split' : [2, 5, 10, 15, 25, 100],\n",
    "    'randomforestclassifier__max_features': uniform(0, 1),\n",
    "    'randomforestclassifier__min_samples_leaf' : [1, 2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "# If you're on Colab, decrease n_iter & cv parameters\n",
    "search = RandomizedSearchCV(\n",
    "    rf, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=10, \n",
    "    scoring='accuracy', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);\n",
    "\n",
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation Accuracy', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters {'randomforestclassifier__max_depth': 15, 'randomforestclassifier__max_features': 0.2972473260117179, 'randomforestclassifier__min_samples_leaf': 10, 'randomforestclassifier__min_samples_split': 15, 'randomforestclassifier__n_estimators': 300}\n",
    "Cross-validation Accuracy -0.6818181818181818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   4 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-2)]: Done  11 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-2)]: Done  18 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=-2)]: Done  27 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-2)]: Done  47 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-2)]: Done  58 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-2)]: Done  71 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-2)]: Done  84 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-2)]: Done  98 out of 100 | elapsed:  7.2min remaining:    8.7s\n",
      "[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'xgbclassifier__subsample': 0.5, 'xgbclassifier__n_estimators': 10, 'xgbclassifier__max_depth': 10, 'xgbclassifier__colsample_bytree': 0.5}\n",
      "Cross-validation Accuracy -0.6572481572481572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Create XGBoost\n",
    "xg = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    XGBClassifier(random_state = 42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'xgbclassifier__n_estimators': [10, 50, 100, 300, 500],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, 15], \n",
    "    'xgbclassifier__subsample' : [0.5, 0.75, 1],\n",
    "    'xgbclassifier__colsample_bytree': [0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "# If you're on Colab, decrease n_iter & cv parameters\n",
    "search = RandomizedSearchCV(\n",
    "    xg, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=10,\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);\n",
    "\n",
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation Accuracy', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters {'xgbclassifier__subsample': 0.5, 'xgbclassifier__n_estimators': 10, 'xgbclassifier__max_depth': 10, 'xgbclassifier__colsample_bytree': 0.5}\n",
    "Cross-validation Accuracy -0.6572481572481572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
