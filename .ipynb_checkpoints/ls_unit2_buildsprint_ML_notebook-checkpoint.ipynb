{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Survey Data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "url = 'https://ndownloader.figshare.com/files/18543320?private_link=74a5ea79d76ad66a8af8'\n",
    "\n",
    "#Extract Columns\n",
    "survey = pd.read_excel(url)\n",
    "raw_cols = survey.columns\n",
    "\n",
    "#Create df\n",
    "df = pd.read_excel(url, header=None, skiprows = 2, names = raw_cols)\n",
    "\n",
    "# #Set data path\n",
    "# d_path = 'data/'\n",
    "\n",
    "# #Import survey data from .csv\n",
    "# df = pd.read_csv(d_path + 'nature_phdsurvey_2019.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a function to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to clean data\n",
    "#The data dictionary provided with the article does not match the dataset well. Check readme for explanation as to why I removed some columns. I think the question #'s got mislabeled somehow.\n",
    "\n",
    "def clean_data(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    print(f'The survey dataset was originally {X.shape}')\n",
    "    \n",
    "    #Filter out 300 rows that chose to not answer target question (those that preferred not to answer)\n",
    "    X = X[((X['Q28'] == 'Yes') | (X['Q28'] == 'No'))]\n",
    "    \n",
    "    #Drop columns containing unique metadata for each test\n",
    "    X = X.drop(columns = ['ID.format', 'ID.endDate', 'ID.completed', 'ID.site', 'ID.date', 'ID.start', 'ID.end', 'ID.time'])\n",
    "    \n",
    "    #Drop columns with extra / specific data. Most are a step down from 'Other' answers in survey\n",
    "    X = X.drop(columns = ['Q1.a', 'Q2', 'Q3.a', 'Q6', 'Q6.a', 'Q7', 'Q7.a', 'Q8', 'Q8.a', 'Q9', 'Q9.a', 'Q10', 'Q10.a', 'Q11', 'Q11.a',\n",
    "                         'Q12.a', 'Q14', 'Q14.a', 'Q15.a', 'Q15.b', 'Q15.c', 'Q15.d', 'Q15.e', 'Q15.f', 'Q15.g', 'Q15.h', 'Q15.i', 'Q15.j',\n",
    "                          'Q15.k', 'Q15.l', 'Q15.m', 'Q15.n', 'Q16','Q17.a', 'Q25.a', 'Q26', 'Q29', 'Q29.a', 'Q32:1', 'Q32:2', 'Q32:3', 'Q32:4', \n",
    "                          'Q32:5', 'Q32:6', 'Q32:7', 'Q32.a', 'Q33', 'Q35:1', 'Q35:2', 'Q35:3', 'Q35:4', 'Q35:5', 'Q35:6', 'Q35:7', 'Q35:8', 'Q35:9', \n",
    "                          'Q35.a', 'Q36.a','Q37.a', 'Q37.b', 'Q37.c', 'Q37.d', 'Q37.e','Q39:1', 'Q39:2', 'Q39:3', 'Q39:4', 'Q39:5', 'Q39:6', 'Q39:7', 'Q39.a',\n",
    "                          'Q39:8', 'Q39:9', 'Q39:1', 'Q39:2', 'Q39:3', 'Q39:4', 'Q39:5', 'Q39:6', 'Q39:7', 'Q39:8', 'Q39:9','Q39.a', 'Q40.a', 'Q41', 'Q44', 'Q44.a', \n",
    "                          'Q45:1', 'Q45:2', 'Q45:3', 'Q45:4', 'Q45:5', 'Q45:6', 'Q45:7', 'Q45:8', 'Q45:9', 'Q45:10', 'Q45:11', 'Q45.a', 'Q46:1', 'Q46:2', 'Q46:3', 'Q46:4', 'Q46:5', 'Q46:6', 'Q46:7', 'Q46:8', 'Q46:9', 'Q46:10', 'Q46:11', 'Q46:12', \n",
    "                          'Q46:13', 'Q46:14', 'Q46.a', 'Q48:1', 'Q48:2', 'Q48:3', 'Q59:5', 'Q59.a', 'Q60', 'Q61', 'Q62', 'Q63', 'Q64', 'Q65.a', 'Q65.b',\n",
    "                          'Q48:4', 'Q48:5', 'Q48:6', 'Q48:7', 'Q48.a', 'Q49:8', 'Q49.a', 'Q52.a', 'Q53:1', 'Q53:2', 'Q53:3', 'Q53:4', 'Q53:5', 'Q53:6', 'Q53:7', \n",
    "                          'Q53.a', 'Q54:5', 'Q54.a', 'Q55', 'Q58.a', 'Q59:1', 'Q59:2', 'Q59:3', 'Q47.a'])\n",
    "    \n",
    "    #Q3 Replace 'Other, please specify with other'\n",
    "    X['Q3'] = X['Q3'].replace('Other, please specify', 'Other')\n",
    "    \n",
    "    #Q4: Are you studying where you grew up?\n",
    "    X['Q4'] = X['Q4'].replace('yes', 1)\n",
    "    X['Q4'] = X['Q4'].replace('no', 0)\n",
    "    \n",
    "    #Q12:1-:12 1 or 0 if they went to graduate school for this reason\n",
    "    Q12_ans = ['Q12:1', 'Q12:2', 'Q12:3', \"Q12:4\", 'Q12:5', 'Q12:6', 'Q12:7', 'Q12:8', 'Q12:9', 'Q12:10', 'Q12:11']\n",
    "    for i in Q12_ans:\n",
    "        X[i].fillna(0, inplace= True)\n",
    "    X['Q12:1'] = (X['Q12:1'].replace('To study at a specific university', 1))\n",
    "    X['Q12:2'] = (X['Q12:2'].replace('Lack of quality PhD programmes in my home country', 1))\n",
    "    X['Q12:3'] = (X['Q12:3'].replace('Lack of funding opportunities in my home country', 1))\n",
    "    X['Q12:4'] = (X['Q12:4'].replace('Lack of PhD programmes in my subject of choice', 1))\n",
    "    X['Q12:5'] = (X['Q12:5'].replace('Chance to pursue a specific research question', 1))\n",
    "    X['Q12:6'] = (X['Q12:6'].replace('Higher salaries post-study', 1))\n",
    "    X['Q12:7'] = (X['Q12:7'].replace('More job opportunities post-study', 1))\n",
    "    X['Q12:8'] = (X['Q12:8'].replace('Family reasons', 1))\n",
    "    X['Q12:9'] = (X['Q12:9'].replace('To experience another culture', 1))\n",
    "    X['Q12:10'] = (X['Q12:10'].replace('Political reasons', 1))\n",
    "    X['Q12:11'] = (X['Q12:11'].replace('Other, please specify', 1))\n",
    "    \n",
    "    #Q18a - How satisfied are you with your decision to pursue a phd?\n",
    "    X['Q18.a'] = (X['Q18.a'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    \n",
    "    #Q19a - How satisfied are you with your phd experience?\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('4 = Neither satisfied nor dissatisfied', 4))\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('1 = Not at all satisfied', 1))\n",
    "    X['Q19.a'] = (X['Q19.a'].replace('7 = Extremely satisfied', 7))\n",
    "    \n",
    "    #Q21a:i & Q22a:i - How satisfied are you with x (Ordinal)\n",
    "    q_21s = ['Q21.a', 'Q21.b', 'Q21.c', 'Q21.d', 'Q21.e', 'Q21.f', 'Q21.g', 'Q21.h', 'Q21.i', 'Q22.a', 'Q22.b', 'Q22.c', 'Q22.d', 'Q22.e', 'Q22.f', 'Q22.g', 'Q22.h', 'Q22.i']\n",
    "    for every in q_21s:\n",
    "        X[q_21s] = (X[q_21s].replace('4 = Neither satisfied nor dissatisfied', 4))\n",
    "        X[q_21s] = (X[q_21s].replace('1 = Not at all satisfied', 1))\n",
    "        X[q_21s] = (X[q_21s].replace('7 = Extremely satisfied', 7))\n",
    "        \n",
    "    #Q24 Workload on average (Ordinal)\n",
    "    X['Q24'] = (X['Q24'].replace('41-50 hours','41-50'))\n",
    "    X['Q24'] = (X['Q24'].replace('51-60 hours','51-60'))\n",
    "    X['Q24'] = (X['Q24'].replace('61-70 hours','61-70'))\n",
    "    X['Q24'] = (X['Q24'].replace('71-80 hours','71-80'))\n",
    "    X['Q24'] = (X['Q24'].replace('21-30 hours','21-30'))\n",
    "    X['Q24'] = (X['Q24'].replace('31-40 hours','31-40'))\n",
    "    X['Q24'] = (X['Q24'].replace('Less than 11 hours','0-10'))\n",
    "    X['Q24'] = (X['Q24'].replace('More than 80 hours','81 and up'))\n",
    "    \n",
    "    #Q25.a - extra for other\n",
    "    X['Q25'] = (X['Q25'].replace('Other, please specify', 'Other'))\n",
    "    \n",
    "    #Q30.a - Q30.f - strongly agree or disagree\n",
    "    X['Q30.a'] = (X['Q30.a'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.b'] = (X['Q30.b'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.c'] = (X['Q30.c'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.d'] = (X['Q30.d'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.e'] = (X['Q30.e'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "    X['Q30.f'] = (X['Q30.f'].replace('Neither satisfied nor dissatisfied', 'Neither'))\n",
    "\n",
    "    #Q34 Did you feel discriminated against or harassed? No issue\n",
    "    X['Q34'].fillna('Prefer not to say', inplace=True)\n",
    "    \n",
    "    #Q47 : Which of these are most difficult based on your discipline\n",
    "    X['Q47:1'] = (X['Q47:1'].replace('Learning what career possibilities exist', 1))\n",
    "    X['Q47:2'] = (X['Q47:2'].replace('Finding research careers within academia', 1))\n",
    "    X['Q47:3'] = (X['Q47:3'].replace('Finding research careers within industry', 1))\n",
    "    X['Q47:4'] = (X['Q47:4'].replace('Finding research careers within government', 1))\n",
    "    X['Q47:5'] = (X['Q47:5'].replace('Finding research careers within charity/non-profit', 1))\n",
    "    X['Q47:6'] = (X['Q47:6'].replace('Obtaining skills for careers in industry', 1))\n",
    "    X['Q47:7'] = (X['Q47:7'].replace('Obtaining skills for careers in non-profits \\xa0', 1))\n",
    "    X['Q47:8'] = (X['Q47:8'].replace('Finding non-research careers that use my skills', 1))\n",
    "    X['Q47:1'].fillna(0, inplace= True)\n",
    "    X['Q47:2'].fillna(0, inplace= True)\n",
    "    X['Q47:3'].fillna(0, inplace= True)\n",
    "    X['Q47:4'].fillna(0, inplace= True)\n",
    "    X['Q47:5'].fillna(0, inplace= True)\n",
    "    X['Q47:6'].fillna(0, inplace= True)\n",
    "    X['Q47:7'].fillna(0, inplace= True)\n",
    "    X['Q47:8'].fillna(0, inplace= True)\n",
    "    \n",
    "    #Q49 - Which of the following do you think is needed\n",
    "    X['Q49:1'].fillna(0, inplace= True)\n",
    "    X['Q49:2'].fillna(0, inplace= True)\n",
    "    X['Q49:3'].fillna(0, inplace= True)\n",
    "    X['Q49:4'].fillna(0, inplace= True)\n",
    "    X['Q49:5'].fillna(0, inplace= True)\n",
    "    X['Q49:6'].fillna(0, inplace= True)\n",
    "    X['Q49:1'] = (X['Q49:1'].replace('Lower competition for grants', 1))\n",
    "    X['Q49:2'] = (X['Q49:2'].replace('Mentorship with individuals in my field/department/institution', 1))\n",
    "    X['Q49:3'] = (X['Q49:3'].replace('Gender-specific mentorship with individuals in my field/department/institution', 1))\n",
    "    X['Q49:4'] = (X['Q49:4'].replace('Better data/information about available career opportunities', 1))\n",
    "    X['Q49:5'] = (X['Q49:5'].replace('A record of, or data on, career paths of previous graduates from my programme', 1))\n",
    "    X['Q49:6'] = (X['Q49:6'].replace('More jobs in academia', 1))\n",
    "    X['Q49:7'] = (X['Q49:7'].replace('Grants to help PhD holders transition to permanent positions', 1))\n",
    "    \n",
    "    #Q52:1 - 52:8 Which, if any, of the following activities have you done to advance your career? \n",
    "    X['Q52:1'].fillna(0, inplace= True)\n",
    "    X['Q52:2'].fillna(0, inplace= True)\n",
    "    X['Q52:3'].fillna(0, inplace= True)\n",
    "    X['Q52:4'].fillna(0, inplace= True)\n",
    "    X['Q52:5'].fillna(0, inplace= True)\n",
    "    X['Q52:6'].fillna(0, inplace= True)\n",
    "    X['Q52:7'].fillna(0, inplace= True)\n",
    "    X['Q52:8'].fillna(0, inplace= True)\n",
    "    X['Q52:1'] = (X['Q52:1'].replace('Attended career seminars and/or workshops',1)) \n",
    "    X['Q52:2'] = (X['Q52:2'].replace('Attended networking events',1))\n",
    "    X['Q52:3'] = (X['Q52:3'].replace('Developed my social media profile',1))\n",
    "    X['Q52:4'] = (X['Q52:4'].replace('Worked out an individualized development plan',1))\n",
    "    X['Q52:5'] = (X['Q52:5'].replace('Discussed my career future with a supervisor/PI',1))\n",
    "    X['Q52:6'] = (X['Q52:6'].replace('Discussed my career future with a mentor',1))\n",
    "    X['Q52:7'] = (X['Q52:7'].replace('Discussed my career future with a careers counsellor at my institution',1))\n",
    "    X['Q52:8'] = (X['Q52:8'].replace('Other, please specify',1))\n",
    "    \n",
    "    #Q54:1\tQ54:2 Q54:3 Q54:4 Q54:5 Q54.a what would you do differently\n",
    "    X['Q54:1'].fillna(0, inplace= True)\n",
    "    X['Q54:2'].fillna(0, inplace= True)\n",
    "    X['Q54:3'].fillna(0, inplace= True)\n",
    "    X['Q54:4'].fillna(0, inplace= True)\n",
    "    X['Q54:1'] = (X['Q54:1'].replace('Change area of study',1))\n",
    "    X['Q54:2'] = (X['Q54:2'].replace('Change supervisor/PI ',1))\n",
    "    X['Q54:3'] = (X['Q54:3'].replace('Not pursue a PhD at all',1))\n",
    "    X['Q54:4'] = (X['Q54:4'].replace('Nothing',1))\n",
    "\n",
    "    #Q58\n",
    "    X['Q58:1'].fillna(0, inplace= True)\n",
    "    X['Q58:2'].fillna(0, inplace= True)\n",
    "    X['Q58:3'].fillna(0, inplace= True)\n",
    "    X['Q58:4'].fillna(0, inplace= True)\n",
    "    X['Q58:5'].fillna(0, inplace= True)\n",
    "    X['Q58:6'].fillna(0, inplace= True)\n",
    "    X['Q58:7'].fillna(0, inplace= True)\n",
    "    X['Q58:8'].fillna(0, inplace= True)\n",
    "    X['Q58:9'].fillna(0, inplace= True)\n",
    "    X['Q58:10'].fillna(0, inplace= True)\n",
    "    X['Q58:11'].fillna(0, inplace= True)\n",
    "    X['Q58:12'].fillna(0, inplace= True)\n",
    "    X['Q58:1'] = (X['Q58:1'].replace('Caucasian',1))\n",
    "    X['Q58:2'] = (X['Q58:2'].replace('Latino/Hispanic',1))\n",
    "    X['Q58:3'] = (X['Q58:3'].replace('Middle Eastern',1))\n",
    "    X['Q58:4'] = (X['Q58:4'].replace('African',1))\n",
    "    X['Q58:5'] = (X['Q58:5'].replace('Caribbean',1))\n",
    "    X['Q58:6'] = (X['Q58:6'].replace('South Asian',1))\n",
    "    X['Q58:7'] = (X['Q58:7'].replace('East Asian',1))\n",
    "    X['Q58:8'] = (X['Q58:8'].replace('Pacific Islander',1))\n",
    "    X['Q58:9'] = (X['Q58:9'].replace('American Indian',1))\n",
    "    X['Q58:10'] = (X['Q58:10'].replace('Mixed ethnicity',1))\n",
    "    X['Q58:11'] = (X['Q58:11'].replace('Other, please specify',1))\n",
    "    X['Q58:12'] = (X['Q58:12'].replace('Prefer not to say',1))\n",
    "\n",
    "    #Q59\n",
    "    X['Q59:4'] = X['Q59:4'].replace('No', 0)\n",
    "    X['Q59:4'].fillna(1, inplace= True)\n",
    "    \n",
    "    #Print out new shape after wrangling\n",
    "    print(f'After wrangling, the dataset is {X.shape}')\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test sets, X feature matrix, and y target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df,train_size = 0.9, random_state = 42)\n",
    "train, val = train_test_split(train, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The survey dataset was originally (4597, 274)\n",
      "After wrangling, the dataset is (4393, 126)\n",
      "The survey dataset was originally (1533, 274)\n",
      "After wrangling, the dataset is (1464, 126)\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe from raw data\n",
    "train = clean_data(train)\n",
    "val = clean_data(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature matrix and target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_test is (4393, 125)\n",
      "The shape of y_test is (4393,)\n",
      "The model will be built to predict whether an individual will reach out for help with anxiety and depression (Q28)\n",
      "The shape of X_test is (1464, 125)\n",
      "The shape of y_test is (1464,)\n"
     ]
    }
   ],
   "source": [
    "#Creating X_test, y_test from features, target\n",
    "X_train = train.drop(columns='Q28')\n",
    "features = X_train.columns.tolist()\n",
    "target = 'Q28'\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns='Q28')\n",
    "y_val = val[target]\n",
    "\n",
    "print(f'The shape of X_test is {X_train.shape}')\n",
    "print(f'The shape of y_test is {y_train.shape}')\n",
    "print(f'The model will be built to predict whether an individual will reach out for help with anxiety and depression ({target})')\n",
    "print(f'The shape of X_test is {X_val.shape}')\n",
    "print(f'The shape of y_test is {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6253129979512861"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#Sklearn baseline (sklearn dummyclassifier)\n",
    "\n",
    "X_baseline = train.drop(columns='Q28')\n",
    "y_baseline = train['Q28']\n",
    "\n",
    "#Create baseline model\n",
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(X_baseline, y_baseline)\n",
    "\n",
    "\n",
    "baseline.score(X_baseline, y_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic baseline accuracy: 0.6924652856817665\n"
     ]
    }
   ],
   "source": [
    "#Create logistic regression baseline\n",
    "log_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    LogisticRegression(solver = 'lbfgs',n_jobs = -1, random_state = 42, max_iter = 1000, verbose = 5)\n",
    ")\n",
    "\n",
    "log_model = log_pipeline.fit(X_train, y_train)\n",
    "print('Logistic baseline accuracy:', log_model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-2)]: Done   7 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-2)]: Done  12 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-2)]: Done  26 tasks      | elapsed:   46.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6b997a963ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best hyperparameters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Create random forest pipeline\n",
    "rf = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    RandomForestClassifier(random_state = 42, n_jobs = -1)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__n_estimators': [10, 50, 100, 300, 500],\n",
    "    'randomforestclassifier__max_depth': [5, 8, 10, 15, 20, None], \n",
    "    'randomforestclassifier__min_samples_split' : [2, 5, 10, 15, 25, 100],\n",
    "    'randomforestclassifier__max_features': uniform(0, 1),\n",
    "    'randomforestclassifier__min_samples_leaf' : [1, 2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "# If you're on Colab, decrease n_iter & cv parameters\n",
    "search = RandomizedSearchCV(\n",
    "    rf, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=10, \n",
    "    scoring='accuracy', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);\n",
    "\n",
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation Accuracy', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters {'randomforestclassifier__max_depth': 15, 'randomforestclassifier__max_features': 0.2972473260117179, 'randomforestclassifier__min_samples_leaf': 10, 'randomforestclassifier__min_samples_split': 15, 'randomforestclassifier__n_estimators': 300}\n",
    "Cross-validation Accuracy -0.6818181818181818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run model with selected hyperparameters\n",
    "#Create random forest model to find permutation importances\n",
    "rfpl = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    RandomForestClassifier(max_depth=15, max_features=0.3,n_estimators=300,min_samples_split=15, min_samples_leaf=10, random_state = 42, n_jobs = -1)\n",
    ")\n",
    "\n",
    "rfpl.fit(X_train, y_train)\n",
    "pipe_score = rfpl.score(X_val, y_val)\n",
    "print(f'Validation accuracy: {pipe_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Create XGBoost\n",
    "xg = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    XGBClassifier(random_state = 42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'xgbclassifier__n_estimators': [10, 50, 100, 300, 500],\n",
    "    'xgbclassifier__max_depth': [3, 5, 7, 10, 15], \n",
    "    'xgbclassifier__subsample' : [0.5, 0.75, 1],\n",
    "    'xgbclassifier__colsample_bytree': [0.5, 0.75, 1]\n",
    "}\n",
    "\n",
    "# If you're on Colab, decrease n_iter & cv parameters\n",
    "search = RandomizedSearchCV(\n",
    "    xg, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=10, \n",
    "    cv=10,\n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-2\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);\n",
    "\n",
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation Accuracy', -search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters {'xgbclassifier__subsample': 0.5, 'xgbclassifier__n_estimators': 10, 'xgbclassifier__max_depth': 10, 'xgbclassifier__colsample_bytree': 0.5}\n",
    "Cross-validation Accuracy -0.6572481572481572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run model with selected hyperparameters\n",
    "#Create xgboost model to find permutation importances\n",
    "xgbpl = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder(),\n",
    "    XGBClassifier(subsample = 0.5, n_estimators =10, max_depth =10, colsample_bytree = 0.5, random_state = 42)\n",
    ")\n",
    "\n",
    "xgbpl.fit(X_train, y_train)\n",
    "pipe_score = xgbpl.score(X_val, y_val)\n",
    "print(f'Validation accuracy: {pipe_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build permuter\n",
    "permuter = PermutationImportance(\n",
    "    model,\n",
    "    scoring='accuracy',\n",
    "    n_iter=7,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run model with selected hyperparameters\n",
    "#Create xgboost model to find permutation importances\n",
    "tformer = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    ce.OrdinalEncoder()\n",
    ")\n",
    "X_train_transformed = tformer.fit_transform(X_train)\n",
    "X_val_transformed = tformer.fit_transform(X_val)\n",
    "\n",
    "xgbpl = XGBClassifier(subsample = 0.5, n_estimators =10, max_depth =10, colsample_bytree = 0.5, random_state = 42)\n",
    "xgbpl.fit(X_train_transformed, y_train)\n",
    "pipe_score = xgbpl.score(X_val_transformed, y_val)\n",
    "print(f'Validation accuracy: {pipe_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
